{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e10becc-11cf-4cf5-bea9-ab49f0f8623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import ArxivLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "import os \n",
    "import getpass\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a7c04c-a211-48ae-97bf-90bdb25445fd",
   "metadata": {},
   "source": [
    "### Arxivloader ###\n",
    "\n",
    "Info. - https://python.langchain.com/v0.2/docs/integrations/document_loaders/arxiv/\n",
    "\n",
    "This would be super helpful as this will help u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c338ef84-c75d-4fc3-8173-0195f8f4a9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Getting relevant paper from arxiv #####\n",
    "\n",
    "# ['metadata','page_content']\n",
    "query = \"recent progress on theoretical studies of twisted MoTe2\"\n",
    "arxiv_docs = ArxivLoader(query=query, load_max_docs=3, load_all_available_meta=True).load() #### Loads number of paper given the query\n",
    "arxiv_docs = ArxivLoader(query=query, load_max_docs=3, load_all_available_meta=True).get_summaries_as_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bbcd8903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mArxivLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mquery\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdoc_content_chars_max\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Load a query result from `Arxiv`.\n",
      "The loader converts the original PDF format into the text.\n",
      "\n",
      "Setup:\n",
      "    Install ``arxiv`` and ``PyMuPDF`` packages.\n",
      "    ``PyMuPDF`` transforms PDF files downloaded from the arxiv.org site\n",
      "    into the text format.\n",
      "\n",
      "    .. code-block:: bash\n",
      "\n",
      "        pip install -U arxiv pymupdf\n",
      "\n",
      "\n",
      "Instantiate:\n",
      "    .. code-block:: python\n",
      "\n",
      "        from langchain_community.document_loaders import ArxivLoader\n",
      "\n",
      "        loader = ArxivLoader(\n",
      "            query=\"reasoning\",\n",
      "            # load_max_docs=2,\n",
      "            # load_all_available_meta=False\n",
      "        )\n",
      "\n",
      "Load:\n",
      "    .. code-block:: python\n",
      "\n",
      "        docs = loader.load()\n",
      "        print(docs[0].page_content[:100])\n",
      "        print(docs[0].metadata)\n",
      "\n",
      "    .. code-block:: python\n",
      "        Understanding the Reasoning Ability of Language Models\n",
      "        From the Perspective of Reasoning Paths Aggre\n",
      "        {\n",
      "            'Published': '2024-02-29',\n",
      "            'Title': 'Understanding the Reasoning Ability of Language Models From the\n",
      "                    Perspective of Reasoning Paths Aggregation',\n",
      "            'Authors': 'Xinyi Wang, Alfonso Amayuelas, Kexun Zhang, Liangming Pan,\n",
      "                    Wenhu Chen, William Yang Wang',\n",
      "            'Summary': 'Pre-trained language models (LMs) are able to perform complex reasoning\n",
      "                    without explicit fine-tuning...'\n",
      "        }\n",
      "\n",
      "\n",
      "Lazy load:\n",
      "    .. code-block:: python\n",
      "\n",
      "        docs = []\n",
      "        docs_lazy = loader.lazy_load()\n",
      "\n",
      "        # async variant:\n",
      "        # docs_lazy = await loader.alazy_load()\n",
      "\n",
      "        for doc in docs_lazy:\n",
      "            docs.append(doc)\n",
      "        print(docs[0].page_content[:100])\n",
      "        print(docs[0].metadata)\n",
      "\n",
      "    .. code-block:: python\n",
      "\n",
      "        Understanding the Reasoning Ability of Language Models\n",
      "        From the Perspective of Reasoning Paths Aggre\n",
      "        {\n",
      "            'Published': '2024-02-29',\n",
      "            'Title': 'Understanding the Reasoning Ability of Language Models From the\n",
      "                    Perspective of Reasoning Paths Aggregation',\n",
      "            'Authors': 'Xinyi Wang, Alfonso Amayuelas, Kexun Zhang, Liangming Pan,\n",
      "                    Wenhu Chen, William Yang Wang',\n",
      "            'Summary': 'Pre-trained language models (LMs) are able to perform complex reasoning\n",
      "                    without explicit fine-tuning...'\n",
      "        }\n",
      "\n",
      "Async load:\n",
      "    .. code-block:: python\n",
      "\n",
      "        docs = await loader.aload()\n",
      "        print(docs[0].page_content[:100])\n",
      "        print(docs[0].metadata)\n",
      "\n",
      "    .. code-block:: python\n",
      "\n",
      "        Understanding the Reasoning Ability of Language Models\n",
      "        From the Perspective of Reasoning Paths Aggre\n",
      "        {\n",
      "            'Published': '2024-02-29',\n",
      "            'Title': 'Understanding the Reasoning Ability of Language Models From the\n",
      "                    Perspective of Reasoning Paths Aggregation',\n",
      "            'Authors': 'Xinyi Wang, Alfonso Amayuelas, Kexun Zhang, Liangming Pan,\n",
      "                    Wenhu Chen, William Yang Wang',\n",
      "            'Summary': 'Pre-trained language models (LMs) are able to perform complex reasoning\n",
      "                    without explicit fine-tuning...'\n",
      "        }\n",
      "\n",
      "Use summaries of articles as docs:\n",
      "    .. code-block:: python\n",
      "\n",
      "        from langchain_community.document_loaders import ArxivLoader\n",
      "\n",
      "        loader = ArxivLoader(\n",
      "            query=\"reasoning\"\n",
      "        )\n",
      "\n",
      "        docs = loader.get_summaries_as_docs()\n",
      "        print(docs[0].page_content[:100])\n",
      "        print(docs[0].metadata)\n",
      "\n",
      "    .. code-block:: python\n",
      "\n",
      "        Pre-trained language models (LMs) are able to perform complex reasoning\n",
      "        without explicit fine-tuning\n",
      "        {\n",
      "            'Entry ID': 'http://arxiv.org/abs/2402.03268v2',\n",
      "            'Published': datetime.date(2024, 2, 29),\n",
      "            'Title': 'Understanding the Reasoning Ability of Language Models From the\n",
      "                    Perspective of Reasoning Paths Aggregation',\n",
      "            'Authors': 'Xinyi Wang, Alfonso Amayuelas, Kexun Zhang, Liangming Pan,\n",
      "                    Wenhu Chen, William Yang Wang'\n",
      "        }\n",
      "\u001b[0;31mInit docstring:\u001b[0m\n",
      "Initialize with search query to find documents in the Arxiv.\n",
      "Supports all arguments of `ArxivAPIWrapper`.\n",
      "\n",
      "Args:\n",
      "    query: free text which used to find documents in the Arxiv\n",
      "    doc_content_chars_max: cut limit for the length of a document's content\n",
      "\u001b[0;31mFile:\u001b[0m           /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain_community/document_loaders/arxiv.py\n",
      "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "?ArxivLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0dfefab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"id\"\n",
      "\"metadata\"\n",
      "\"page_content\"\n",
      "\"type\"\n",
      "\"is_lc_serializable\"\n",
      "\"get_lc_namespace\"\n",
      "\"lc_secrets\"\n",
      "\"lc_attributes\"\n",
      "\"lc_id\"\n",
      "\"Config\"\n",
      "\"to_json\"\n",
      "\"to_json_not_implemented\"\n",
      "\"dict\"\n",
      "\"json\"\n",
      "\"parse_obj\"\n",
      "\"parse_raw\"\n",
      "\"parse_file\"\n",
      "\"from_orm\"\n",
      "\"construct\"\n",
      "\"copy\"\n",
      "\"schema\"\n",
      "\"schema_json\"\n",
      "\"validate\"\n",
      "\"update_forward_refs\"\n"
     ]
    }
   ],
   "source": [
    "for s in arxiv_docs[0].__dir__():\n",
    "    if s[0]!='_':\n",
    "        print('\"'+s+'\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e5380f-d927-48f5-9473-8dd2e3df1a7f",
   "metadata": {},
   "source": [
    "### Text splitting ###\n",
    "Info - https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/recursive_text_splitter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eef99f1-1603-4155-9ab4-29ec7a28567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### splitting data ####\n",
    "\n",
    "## added metadatas = [doc.metadata] to each chunk of data\n",
    "pdf_data = []\n",
    "for doc in arxiv_docs:\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "                    chunk_size=500,\n",
    "                    chunk_overlap=10)\n",
    "    texts = text_splitter.create_documents(texts=[doc.page_content],metadatas=[doc.metadata])\n",
    "    # pdf_data.append(texts)\n",
    "    for j in range(len(texts)):\n",
    "        pdf_data.append(texts[j])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bddfcaa-b0a2-42d3-83b2-8fd94d3868a6",
   "metadata": {},
   "source": [
    "### Embedding ####\n",
    "\n",
    "Info - https://python.langchain.com/v0.2/docs/integrations/platforms/huggingface/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2e0b6e-7ced-445e-a8fa-ccc5ec9f2a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "## embe\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-l6-v2\")\n",
    "db = Chroma.from_documents(documents = pdf_data, embedding= embeddings) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31919081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mChroma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdocuments\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'List[Document]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0membedding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[Embeddings]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[List[str]]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcollection_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'langchain'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpersist_directory\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[str]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mclient_settings\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[chromadb.config.Settings]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mclient\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[chromadb.Client]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcollection_metadata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[Dict]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Any'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'Chroma'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Create a Chroma vectorstore from a list of documents.\n",
      "\n",
      "If a persist_directory is specified, the collection will be persisted there.\n",
      "Otherwise, the data will be ephemeral in-memory.\n",
      "\n",
      "Args:\n",
      "    collection_name (str): Name of the collection to create.\n",
      "    persist_directory (Optional[str]): Directory to persist the collection.\n",
      "    ids (Optional[List[str]]): List of document IDs. Defaults to None.\n",
      "    documents (List[Document]): List of documents to add to the vectorstore.\n",
      "    embedding (Optional[Embeddings]): Embedding function. Defaults to None.\n",
      "    client_settings (Optional[chromadb.config.Settings]): Chroma client settings\n",
      "    collection_metadata (Optional[Dict]): Collection configurations.\n",
      "                                          Defaults to None.\n",
      "\n",
      "Returns:\n",
      "    Chroma: Chroma vectorstore.\n",
      "\u001b[0;31mFile:\u001b[0m      /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "?Chroma.from_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fe14ea-39fb-4509-bf60-2d4da5f3765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\",\n",
    "                             temperature=0,\n",
    "                             max_tokens=None,\n",
    "                             timeout=None,\n",
    "                             max_retries=2,)\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                 chain_type=\"stuff\",\n",
    "                                 retriever=db.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3094daa2-fd44-45fd-a293-e95d35464055",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are the topological and correlated phenomena in twisted MoTe2?\"\n",
    "result = qa({\"query\": question})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85597082-c538-431d-9c5b-0e66ae4ee4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Whats the limit on period derivative?\"\n",
    "result = qa({\"query\": question})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f764f9b-e54f-404e-89e6-a48b0aca1716",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Summarize the paper in a paragraph\"\n",
    "result = qa({\"query\": question})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f077363-5c0f-4453-92ea-3b23e0b34897",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Tell me 5 facts about FRB 20180916B\"\n",
    "result = qa({\"query\": question})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521b46b3-c0a3-47ab-86bf-ba95ab4a0b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyDpCp8WUjjaE3mJsOXcdxdlAihxuGjJf7E\")\n",
    "\n",
    "model = genai.GenerativeModel('gemini-1.5-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afe47da",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(\"Write a story about an AI and magic\")\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
