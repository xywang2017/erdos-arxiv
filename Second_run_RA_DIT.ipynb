{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "e2CQi6dkdfqg"
      },
      "id": "e2CQi6dkdfqg"
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "id": "7e10becc-11cf-4cf5-bea9-ab49f0f8623e",
      "metadata": {
        "id": "7e10becc-11cf-4cf5-bea9-ab49f0f8623e"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import ArxivLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_openai import OpenAI\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "import arxiv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2a7c04c-a211-48ae-97bf-90bdb25445fd",
      "metadata": {
        "id": "a2a7c04c-a211-48ae-97bf-90bdb25445fd"
      },
      "source": [
        "### Arxivloader ###\n",
        "\n",
        "Info. - https://python.langchain.com/v0.2/docs/integrations/document_loaders/arxiv/\n",
        "\n",
        "This would be super helpful as this will help u\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "c338ef84-c75d-4fc3-8173-0195f8f4a9fa",
      "metadata": {
        "id": "c338ef84-c75d-4fc3-8173-0195f8f4a9fa"
      },
      "outputs": [],
      "source": [
        "### Getting relevant paper from arxiv #####\n",
        "\n",
        "query = \"FRB 20180916B, \"\n",
        "query = \"The Impact of Positive AGN Feedback on the Properties of Galaxies in a Semi-Analytic Model of Galaxy Formation\"\n",
        "arxiv_docs = ArxivLoader(query=query, load_max_docs=3).load() #### Loads number of paper given the query"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15e5380f-d927-48f5-9473-8dd2e3df1a7f",
      "metadata": {
        "id": "15e5380f-d927-48f5-9473-8dd2e3df1a7f"
      },
      "source": [
        "### Text splitting ###\n",
        "Info - https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/recursive_text_splitter/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "id": "1eef99f1-1603-4155-9ab4-29ec7a28567c",
      "metadata": {
        "id": "1eef99f1-1603-4155-9ab4-29ec7a28567c"
      },
      "outputs": [],
      "source": [
        "##### splitting data ####\n",
        "\n",
        "pdf_data = []\n",
        "for doc in arxiv_docs:\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "                    chunk_size=1000,\n",
        "                    chunk_overlap=100)\n",
        "    texts = text_splitter.create_documents([doc.page_content])\n",
        "    pdf_data.append(texts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bddfcaa-b0a2-42d3-83b2-8fd94d3868a6",
      "metadata": {
        "id": "4bddfcaa-b0a2-42d3-83b2-8fd94d3868a6"
      },
      "source": [
        "### Embedding ####\n",
        "\n",
        "Info - https://python.langchain.com/v0.2/docs/integrations/platforms/huggingface/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "id": "1e2e0b6e-7ced-445e-a8fa-ccc5ec9f2a33",
      "metadata": {
        "id": "1e2e0b6e-7ced-445e-a8fa-ccc5ec9f2a33"
      },
      "outputs": [],
      "source": [
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-l6-v2\")\n",
        "db = Chroma.from_documents(pdf_data[0], embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "id": "1e3afc52-fdcb-4ce4-9911-5aa93cfcf869",
      "metadata": {
        "id": "1e3afc52-fdcb-4ce4-9911-5aa93cfcf869",
        "outputId": "534eaf39-0ae1-4ef2-cbd0-fd3501408c67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google AI API key: ··········\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "96fe14ea-39fb-4509-bf60-2d4da5f3765a",
      "metadata": {
        "id": "96fe14ea-39fb-4509-bf60-2d4da5f3765a"
      },
      "outputs": [],
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\",\n",
        "                             temperature=0,\n",
        "                             max_tokens=None,\n",
        "                             timeout=None,\n",
        "                             max_retries=2,)\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                 chain_type=\"stuff\",\n",
        "                                 retriever=db.as_retriever())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "id": "3094daa2-fd44-45fd-a293-e95d35464055",
      "metadata": {
        "id": "3094daa2-fd44-45fd-a293-e95d35464055",
        "outputId": "ffd890ac-155a-43b2-cb6b-207740d8452f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': 'What was the total exposure on the source?', 'result': 'The total exposure on the source in the aforementioned time interval is 201 hours. \\n'}\n"
          ]
        }
      ],
      "source": [
        "question = \"What was the total exposure on the source?\"\n",
        "result = qa({\"query\": question})\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "id": "85597082-c538-431d-9c5b-0e66ae4ee4e1",
      "metadata": {
        "id": "85597082-c538-431d-9c5b-0e66ae4ee4e1",
        "outputId": "0ed4c729-e48e-42ed-b66b-4962f5775b7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': 'Whats the limit on period derivative?', 'result': \"I'm sorry, but the text provided does not mention a specific limit on the period derivative. It only mentions a value of 1.5 × 10−4 day day−1 for the absolute period derivative. \\n\"}\n"
          ]
        }
      ],
      "source": [
        "question = \"Whats the limit on period derivative?\"\n",
        "result = qa({\"query\": question})\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "id": "0f764f9b-e54f-404e-89e6-a48b0aca1716",
      "metadata": {
        "id": "0f764f9b-e54f-404e-89e6-a48b0aca1716",
        "outputId": "6d505efd-2d75-45db-c1eb-e6f5a437434e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': 'Summarize the paper in a paragraph', 'result': \"I'm sorry, but I cannot summarize the paper based on the provided snippets. The context only provides scattered phrases and doesn't reveal the paper's actual content or arguments.  Please provide more information from the paper for a proper summary. \\n\"}\n"
          ]
        }
      ],
      "source": [
        "question = \"Summarize the paper in a paragraph\"\n",
        "result = qa({\"query\": question})\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "id": "5f077363-5c0f-4453-92ea-3b23e0b34897",
      "metadata": {
        "id": "5f077363-5c0f-4453-92ea-3b23e0b34897",
        "outputId": "ba9be6db-aadc-454f-e691-78d6ac2d8619",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': 'Tell me 7 facts about FRB 20180916B', 'result': 'The provided text only gives us a few details about FRB 20180916B and is not enough to extract 7 facts. \\n\\nHere is what we know:\\n\\n1. **FRB 20180916B has a significantly lower Rotation Measure (RM) than FRB 20121102A.** It is mentioned that the difference is four orders of magnitude.\\n2. **The lower RM of FRB 20180916B suggests something about its immediate environment.** The exact implication is not stated in the provided text. \\n\\nWe need more information to provide 7 facts about FRB 20180916B. \\n'}\n"
          ]
        }
      ],
      "source": [
        "question = \"Tell me 7 facts about FRB 20180916B\"\n",
        "result = qa({\"query\": question})\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "521b46b3-c0a3-47ab-86bf-ba95ab4a0b80",
      "metadata": {
        "id": "521b46b3-c0a3-47ab-86bf-ba95ab4a0b80"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Using Retrieval Augmented Dual Instruction Tuning (RA-DIT)###\n",
        "\n",
        "Info: https://cobusgreyling.medium.com/fine-tuning-llms-with-retrieval-augmented-generation-rag-c66e56aec858\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "DEq7Z3fXKsOQ"
      },
      "id": "DEq7Z3fXKsOQ"
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.core import PromptTemplate\n",
        "#from llama_index.core import SimpleDocument  # Import directly from llama_index\n",
        "\n",
        "# Define the prompt template\n",
        "qa_prompt_tmpl_str = (\n",
        "    \"Context information is below.\\n\"\n",
        "    \"---------------------\\n\"\n",
        "    \"{context_str}\\n\"\n",
        "    \"---------------------\\n\"\n",
        "    \"Given the context information and not prior knowledge, \"\n",
        "    \"answer the query.\\n\"\n",
        "    \"Query: {query_str}\\n\"\n",
        "    \"Answer: \"\n",
        ")\n",
        "qa_prompt_tmpl = PromptTemplate(qa_prompt_tmpl_str)\n",
        "\n",
        "# Create a list of Document objects\n",
        "# Replace with your actual document content\n",
        "#documents = [\n",
        "#    SimpleDocument(text=\"burst rate and morphological evolution of the periodically repeating FRB 20180916B.\"),\n",
        "#    SimpleDocument(text=\"arxiv_docs\")\n",
        "##]\n",
        "\n",
        "#documents = [SimpleDocument(text=text) for text in pdf_data]\n",
        "\n",
        "\n",
        "# Create an instance of VectorStoreIndex\n",
        "vector_index = VectorStoreIndex.from_documents(pdf_data)\n",
        "\n",
        "# Set up the vector retriever\n",
        "vector_retriever = vector_index.as_retriever(similarity_top_k=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "kdyJ64pdLpoO",
        "outputId": "a1f171dc-f969-4a59-dfe0-e56b2729e661"
      },
      "id": "kdyJ64pdLpoO",
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'get_doc_id'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-134-adde656c7994>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Create an instance of VectorStoreIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mvector_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVectorStoreIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Set up the vector retriever\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/indices/base.py\u001b[0m in \u001b[0;36mfrom_documents\u001b[0;34m(cls, documents, storage_context, show_progress, callback_manager, transformations, service_context, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcallback_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"index_construction\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                 \u001b[0mdocstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_document_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_doc_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             nodes = run_transformations(\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'get_doc_id'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_openai_data(dataset, out_path):\n",
        "    # out_fp = open(\"data_rag/qa_pairs_openai.jsonl\", \"w\")\n",
        "    out_fp = open(out_path, \"w\")\n",
        "    # TODO: try with different system prompts\n",
        "    system_prompt = {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a helpful assistant helping to answer questions about the Llama 2 paper.\",\n",
        "    }\n",
        "    train_qr_pairs = dataset.qr_pairs\n",
        "    for line in train_qr_pairs:\n",
        "        query, response = line\n",
        "        user_prompt = {\"role\": \"user\", \"content\": query}\n",
        "        assistant_prompt = {\"role\": \"assistant\", \"content\": response}\n",
        "        out_dict = {\n",
        "            \"messages\": [system_prompt, user_prompt, assistant_prompt],\n",
        "        }\n",
        "        out_fp.write(json.dumps(out_dict) + \"\\n\")\n",
        "save_openai_data(train_dataset, \"data_rag/qa_pairs_openai.jsonl\")"
      ],
      "metadata": {
        "id": "c1-MlhftgeuI"
      },
      "id": "c1-MlhftgeuI",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}